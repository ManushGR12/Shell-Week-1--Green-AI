{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Preprocessing for Org Go Project\n",
        "This notebook covers data loading, cleaning, feature engineering, encoding, scaling, and train-test splits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "import os\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv('data/raw/Crop_recommendation.csv')\n",
        "print(f'Dataset shape: {df.shape}')\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Remove duplicates\n",
        "df.drop_duplicates(inplace=True)\n",
        "\n",
        "# Handle missing values by median (numerical) and mode (categorical)\n",
        "for col in df.columns:\n",
        "    if df[col].isnull().sum() > 0:\n",
        "        if df[col].dtype == 'object':\n",
        "            df[col].fillna(df[col].mode()[0], inplace=True)\n",
        "        else:\n",
        "            df[col].fillna(df[col].median(), inplace=True)\n",
        "\n",
        "print('Missing values after imputation:', df.isnull().sum().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Feature Engineering\n",
        "if set(['N', 'P', 'K']).issubset(df.columns):\n",
        "    df['NPK_sum'] = df['N'] + df['P'] + df['K']\n",
        "    df['N_to_PK_ratio'] = df['N'] / (df['P'] + df['K'] + 1)\n",
        "\n",
        "if set(['temperature', 'humidity']).issubset(df.columns):\n",
        "    df['temp_humidity_ratio'] = df['temperature'] / (df['humidity'] + 1)\n",
        "\n",
        "if 'ph' in df.columns:\n",
        "    df['soil_type'] = pd.cut(df['ph'], bins=[0,6.5,7.5,14], labels=['Acidic', 'Neutral', 'Alkaline'])\n",
        "\n",
        "if 'rainfall' in df.columns:\n",
        "    df['rainfall_category'] = pd.cut(df['rainfall'], bins=[0,50,100,200,float('inf')], labels=['Low', 'Medium', 'High', 'Very High'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Encoding categorical variables\n",
        "label_enc_cols = ['label', 'soil_type', 'rainfall_category']\n",
        "le_dict = {}\n",
        "for col in label_enc_cols:\n",
        "    if col in df.columns:\n",
        "        le = LabelEncoder()\n",
        "        df[col] = df[col].astype(str)\n",
        "        df[col] = le.fit_transform(df[col])\n",
        "        le_dict[col] = le\n",
        "\n",
        "print('Encoding complete.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Feature selection for model training\n",
        "feature_cols = ['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall', 'NPK_sum', 'N_to_PK_ratio', 'temp_humidity_ratio']\n",
        "feature_cols = [col for col in feature_cols if col in df.columns]\n",
        "X = df[feature_cols]\n",
        "y = df['label']\n",
        "\n",
        "# Scaling numerical features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Save the processed data\n",
        "import numpy as np\n",
        "np.savetxt('data/processed/X_train.csv', X_train, delimiter=',')\n",
        "np.savetxt('data/processed/X_test.csv', X_test, delimiter=',')\n",
        "np.savetxt('data/processed/y_train.csv', y_train, delimiter=',')\n",
        "np.savetxt('data/processed/y_test.csv', y_test, delimiter=',')\n",
        "\n",
        "print('Data preprocessing complete. Files saved in data/processed/')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
